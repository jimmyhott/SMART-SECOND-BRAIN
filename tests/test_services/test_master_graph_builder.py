"""
Test script for MasterGraphBuilder workflow.

This module tests the Smart Second Brain master graph builder,
including node methods, graph compilation, and workflow execution.
"""

import pytest
import sys
import os
from pathlib import Path
from unittest.mock import Mock, MagicMock
from typing import Dict, Any
from dotenv import load_dotenv

# Add the project root to the path for imports
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Import centralized logging
from shared.utils.logging_config import setup_test_logging

# Set up test logging
logger = setup_test_logging("test_master_graph_builder")

# Load environment variables from .env file
load_dotenv()

# Add the project root to the path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from agentic.core.knowledge_state import KnowledgeState
from agentic.workflows.master_graph_builder import MasterGraphBuilder

# Import real components for integration testing
try:
    from langchain_openai import ChatOpenAI, AzureChatOpenAI, OpenAIEmbeddings, AzureOpenAIEmbeddings
    from langchain_chroma import Chroma
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain.schema import Document
    REAL_COMPONENTS_AVAILABLE = True
except ImportError:
    REAL_COMPONENTS_AVAILABLE = False
    logger.warning("‚ö†Ô∏è  Real components not available. Install langchain packages for integration tests.")


class TestMasterGraphBuilder:
    """Test suite for MasterGraphBuilder class."""

    @pytest.fixture
    def mock_llm(self):
        """Create a mock LLM client."""
        mock = Mock()
        mock_response = Mock()
        mock_response.content = "This is a test answer generated by the LLM."
        mock.invoke.return_value = mock_response
        return mock

    @pytest.fixture
    def mock_retriever(self):
        """Create a mock document retriever."""
        mock = Mock()
        mock_doc = Mock()
        mock_doc.page_content = "This is a retrieved document for testing."
        mock.get_relevant_documents.return_value = [mock_doc]
        return mock

    @pytest.fixture
    def mock_embedding_model(self):
        """Create a mock embedding model."""
        mock = Mock()
        # Return embeddings based on the number of input documents
        def mock_embed_documents(documents):
            return [[0.1, 0.2, 0.3] for _ in documents]
        mock.embed_documents.side_effect = mock_embed_documents
        return mock

    @pytest.fixture
    def mock_vectorstore(self):
        """Create a mock vector store."""
        mock = Mock()
        mock.add_texts = Mock()
        return mock

    @pytest.fixture
    def graph_builder(self, mock_llm, mock_embedding_model, mock_retriever, mock_vectorstore):
        """Create a MasterGraphBuilder instance with mocked dependencies."""
        return MasterGraphBuilder(
            llm=mock_llm,
            embedding_model=mock_embedding_model,
            retriever=mock_retriever,
            vectorstore=mock_vectorstore
        )

    @pytest.fixture
    def real_graph_builder(self):
        """Create a MasterGraphBuilder instance with real components."""
        if not REAL_COMPONENTS_AVAILABLE:
            pytest.skip("Real components not available")
        
        # Check for OpenAI API key
        openai_api_key = os.getenv("OPENAI_API_KEY")
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT_URL")
        
        if not openai_api_key:
            pytest.skip("OPENAI_API_KEY not set in .env file")
        
        try:
                                    # Get model name from environment
            model_name = os.getenv("LLM_MODEL", "gpt-4o")
            
            # Use Azure OpenAI if endpoint is configured, otherwise use OpenAI
            if azure_endpoint and azure_endpoint != "https://your-resource-name.openai.azure.com/":
                logger.info(f"üîó Using Azure OpenAI endpoint: {azure_endpoint}")
                logger.info(f"ü§ñ Using model: {model_name}")
                
                # Get API version from environment
                api_version = os.getenv("API_VERSION", "2024-02-15-preview")
                
                # Use AzureChatOpenAI for Azure endpoints
                llm = AzureChatOpenAI(
                    azure_deployment=model_name,  # This is the deployment name
                    openai_api_version=api_version,
                    azure_endpoint=azure_endpoint,
                    openai_api_key=openai_api_key,
                    temperature=0
                )
            else:
                logger.info("üîó Using OpenAI API directly")
                logger.info(f"ü§ñ Using model: {model_name}")
                llm = ChatOpenAI(
                    model=model_name,
                    temperature=0,
                    openai_api_key=openai_api_key
                )
            
            # Initialize embedding model
            embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            api_version = os.getenv("API_VERSION", "2024-02-15-preview")
            
            if azure_endpoint and azure_endpoint != "https://your-resource-name.openai.azure.com/":
                # Use AzureOpenAIEmbeddings for Azure endpoints
                deployment = "text-embedding-3-small"
                logger.info(f"üîó Using Azure OpenAI embeddings: {embedding_model}")
                logger.info(f"üöÄ Using deployment: {deployment}")
                embeddings = AzureOpenAIEmbeddings(
                    azure_deployment=deployment,
                    openai_api_version=api_version,
                    azure_endpoint=azure_endpoint,
                    openai_api_key=openai_api_key
                )
            else:
                embeddings = OpenAIEmbeddings(
                    model=embedding_model,
                    openai_api_key=openai_api_key
                )
            
            return MasterGraphBuilder(
                llm=llm,
                embedding_model=embeddings,
                retriever=None,  # Will be set up in individual tests
                vectorstore=None  # Will be set up in individual tests
            )
        except Exception as e:
            pytest.skip(f"Failed to initialize real components: {e}")

    @pytest.fixture
    def sample_documents(self):
        """Create sample documents for testing."""
        return [
            "The Smart Second Brain is an AI-powered knowledge management system that helps users organize and retrieve information efficiently.",
            "Knowledge graphs are powerful tools for representing relationships between concepts and entities in a structured format.",
            "LangGraph is a framework for building stateful, multi-actor applications with LLMs, enabling complex workflows and agent interactions.",
            "Vector databases store high-dimensional embeddings that enable semantic search and similarity matching across large document collections.",
            "Human-in-the-loop systems combine AI automation with human oversight to ensure quality and handle edge cases effectively."
        ]

    @pytest.fixture
    def sample_ingest_state(self):
        """Create a sample knowledge state for ingestion testing."""
        return KnowledgeState(
            query_type="ingest",
            raw_document="This is a test document.\n\nIt has multiple paragraphs.\n\nFor testing purposes.",
            metadata={"source": "test", "timestamp": "2024-01-01T00:00:00Z"}
        )

    @pytest.fixture
    def sample_query_state(self):
        """Create a sample knowledge state for query testing."""
        return KnowledgeState(
            query_type="query",
            user_input="What is the main topic of the document?",
            messages=[{"role": "user", "content": "What is the main topic of the document?"}]
        )

    def test_initialization(self, mock_llm, mock_retriever, mock_vectorstore):
        """Test MasterGraphBuilder initialization."""
        builder = MasterGraphBuilder(
            llm=mock_llm,
            retriever=mock_retriever,
            vectorstore=mock_vectorstore
        )
        
        assert builder.llm == mock_llm
        assert builder.retriever == mock_retriever
        assert builder.vectorstore == mock_vectorstore

    def test_input_router_ingest(self, graph_builder, sample_ingest_state):
        """Test input router for ingest query type."""
        result = graph_builder.input_router(sample_ingest_state)
        assert result == sample_ingest_state

    def test_input_router_query(self, graph_builder, sample_query_state):
        """Test input router for query query type."""
        result = graph_builder.input_router(sample_query_state)
        assert result == sample_query_state

    def test_input_router_unknown(self, graph_builder):
        """Test input router for unknown query type."""
        state = KnowledgeState(query_type="unknown")
        result = graph_builder.input_router(state)
        assert result == state
        assert state.status == "error"
        assert "Unknown query_type" in (state.logs or [])

    def test_chunk_doc_node(self, graph_builder, sample_ingest_state):
        """Test document chunking node."""
        result_state = graph_builder.chunk_doc_node(sample_ingest_state)
        
        assert result_state.chunks is not None
        assert len(result_state.chunks) == 3
        assert "This is a test document." in result_state.chunks[0]
        assert "It has multiple paragraphs." in result_state.chunks[1]
        assert "For testing purposes." in result_state.chunks[2]

    def test_chunk_doc_node_empty_document(self, graph_builder):
        """Test document chunking with empty document."""
        state = KnowledgeState(query_type="ingest", raw_document="")
        result_state = graph_builder.chunk_doc_node(state)
        
        assert result_state.chunks is None

    def test_embed_node(self, graph_builder, sample_ingest_state):
        """Test embedding node with embedding model."""
        # First chunk the document
        state = graph_builder.chunk_doc_node(sample_ingest_state)
        result_state = graph_builder.embed_node(state)
        
        assert result_state.embeddings is not None
        assert len(result_state.embeddings) == len(result_state.chunks)
        # Check that embeddings are lists of floats
        assert all(isinstance(emb, list) for emb in result_state.embeddings)

    def test_embed_node_without_model(self, sample_ingest_state):
        """Test embedding node without embedding model (fallback behavior)."""
        builder = MasterGraphBuilder()  # No embedding model
        state = builder.chunk_doc_node(sample_ingest_state)
        result_state = builder.embed_node(state)
        
        assert result_state.embeddings is not None
        assert len(result_state.embeddings) == len(result_state.chunks)
        # Check that fallback embeddings are used
        assert all(emb == [0.1, 0.2] for emb in result_state.embeddings)

    @pytest.mark.integration
    def test_long_paragraph_chunk_embed_store(self, real_graph_builder):
        """Test processing a long paragraph through chunk, embed, and store workflow."""
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set in .env file")
        
        try:
            # Create a long paragraph for testing
            long_paragraph = """
            The Smart Second Brain is an advanced AI-powered knowledge management system that revolutionizes how individuals and organizations process, store, and retrieve information. Built on cutting-edge technologies including LangGraph for workflow orchestration, Azure OpenAI for natural language processing, and ChromaDB for vector storage, this platform provides intelligent document processing capabilities that go far beyond simple text storage. The system employs sophisticated text chunking algorithms that break down large documents into semantically meaningful pieces, ensuring that context is preserved while optimizing for embedding generation and retrieval. Each chunk is then processed through state-of-the-art embedding models like text-embedding-3-small, which converts text into high-dimensional vector representations that capture semantic meaning and enable powerful similarity searches. The vector database, powered by ChromaDB, stores these embeddings alongside rich metadata including source information, categorization tags, and temporal data, allowing for complex queries that can find relevant information across vast document collections. The platform's retrieval system uses advanced semantic search algorithms to find the most relevant chunks based on user queries, and its answer generation component leverages large language models to synthesize coherent, contextually appropriate responses. What sets this system apart is its human-in-the-loop architecture, which combines AI automation with human oversight to ensure quality, handle edge cases, and provide continuous learning capabilities. The system also features robust error handling, comprehensive logging, and scalable architecture that can handle everything from individual note-taking to enterprise-level knowledge management. Users can interact with the system through multiple interfaces, including natural language queries, document uploads, and API integrations, making it suitable for researchers, content creators, businesses, and anyone who needs to manage large amounts of information effectively. The platform's modular design allows for easy customization and extension, with components that can be swapped out or enhanced based on specific use cases and requirements.
            """
            
            # Create state with long paragraph
            state = KnowledgeState(
                query_type="ingest",
                raw_document=long_paragraph,
                source="test_long_paragraph",
                categories=["ai", "knowledge_management", "technology"],
                metadata={
                    "author": "test_user",
                    "timestamp": "2024-01-01T00:00:00Z",
                    "document_type": "technical_description"
                }
            )
            
            logger.info(f"üìÑ Processing long paragraph ({len(long_paragraph)} characters)")
            
            # Step 1: Chunk the document
            logger.info("üî™ Step 1: Chunking document...")
            state = real_graph_builder.chunk_doc_node(state)
            
            assert state.chunks is not None
            assert len(state.chunks) > 1  # Should be split into multiple chunks
            logger.info(f"‚úÖ Chunked into {len(state.chunks)} chunks")
            
            # Verify chunk sizes are reasonable
            chunk_sizes = [len(chunk) for chunk in state.chunks]
            logger.info(f"üìä Chunk sizes: min={min(chunk_sizes)}, max={max(chunk_sizes)}, avg={sum(chunk_sizes)/len(chunk_sizes):.1f}")
            
            # Step 2: Generate embeddings
            logger.info("üî§ Step 2: Generating embeddings...")
            state = real_graph_builder.embed_node(state)
            
            assert state.embeddings is not None
            assert len(state.embeddings) == len(state.chunks)
            logger.info(f"‚úÖ Generated {len(state.embeddings)} embeddings")
            
            # Verify embedding dimensions
            embedding_dims = [len(emb) for emb in state.embeddings]
            assert all(dim == embedding_dims[0] for dim in embedding_dims)  # All should have same dimensions
            logger.info(f"üî§ Embedding dimensions: {embedding_dims[0]}")
            
            # Step 3: Store in ChromaDB
            logger.info("üíæ Step 3: Storing in ChromaDB...")
            state = real_graph_builder.store_node(state)
            
            assert state.status != "error"
            logger.info(f"‚úÖ Stored successfully in ChromaDB")
            
            # Verify vectorstore was created and populated
            assert real_graph_builder.vectorstore is not None
            
            # Test retrieval from the stored data
            logger.info("üîç Step 4: Testing retrieval...")
            retriever = real_graph_builder.vectorstore.as_retriever(search_kwargs={"k": 3})
            real_graph_builder.retriever = retriever
            
            query_state = KnowledgeState(
                query_type="query",
                user_input="What is the Smart Second Brain system?",
                messages=[{"role": "user", "content": "What is the Smart Second Brain system?"}]
            )
            
            # Run retrieval
            query_state = real_graph_builder.retriever_node(query_state)
            
            assert query_state.retrieved_docs is not None
            assert len(query_state.retrieved_docs) > 0
            logger.info(f"‚úÖ Retrieved {len(query_state.retrieved_docs)} relevant documents")
            
            # Test answer generation
            logger.info("ü§ñ Step 5: Testing answer generation...")
            query_state = real_graph_builder.answer_gen_node(query_state)
            
            assert query_state.generated_answer is not None
            assert len(query_state.generated_answer) > 50
            logger.info(f"‚úÖ Generated answer: {query_state.generated_answer[:100]}...")
            
            # Complete the workflow
            query_state = real_graph_builder.human_review_node(query_state)
            query_state = real_graph_builder.validated_store_node(query_state)
            
            assert query_state.status == "validated"
            logger.info("‚úÖ Complete workflow successful!")
            
            # Summary
            logger.info(f"üìä Workflow Summary:")
            logger.info(f"   - Input: {len(long_paragraph)} characters")
            logger.info(f"   - Chunks: {len(state.chunks)}")
            logger.info(f"   - Embeddings: {len(state.embeddings)}")
            logger.info(f"   - Embedding dimensions: {embedding_dims[0]}")
            logger.info(f"   - Retrieved docs: {len(query_state.retrieved_docs)}")
            logger.info(f"   - Final status: {query_state.status}")
            
        except Exception as e:
            pytest.fail(f"Long paragraph workflow test failed: {e}")

    def test_store_node(self, graph_builder, sample_ingest_state, mock_vectorstore):
        """Test store node with vectorstore."""
        # Prepare state with chunks and embeddings
        state = graph_builder.chunk_doc_node(sample_ingest_state)
        state = graph_builder.embed_node(state)
        result_state = graph_builder.store_node(state)
        
        assert result_state.status == "stored"
        # Verify vectorstore was called
        mock_vectorstore.add_texts.assert_called()

    def test_store_node_no_vectorstore(self, sample_ingest_state):
        """Test store node without vectorstore."""
        builder = MasterGraphBuilder()  # No vectorstore
        state = builder.chunk_doc_node(sample_ingest_state)
        state = builder.embed_node(state)
        result_state = builder.store_node(state)
        
        assert result_state.status == "stored"

    def test_retriever_node(self, graph_builder, sample_query_state, mock_retriever):
        """Test retriever node with retriever."""
        result_state = graph_builder.retriever_node(sample_query_state)
        
        assert result_state.retrieved_docs is not None
        assert len(result_state.retrieved_docs) == 1
        assert "This is a retrieved document for testing." in result_state.retrieved_docs[0]["content"]
        
        # Verify retriever was called
        mock_retriever.get_relevant_documents.assert_called_with(sample_query_state.user_input)

    def test_retriever_node_no_retriever(self, sample_query_state):
        """Test retriever node without retriever."""
        builder = MasterGraphBuilder()  # No retriever
        result_state = builder.retriever_node(sample_query_state)
        
        assert result_state.retrieved_docs is not None
        assert len(result_state.retrieved_docs) == 1
        assert "Dummy retrieved note" in result_state.retrieved_docs[0]["content"]

    def test_answer_gen_node(self, graph_builder, sample_query_state, mock_llm):
        """Test answer generation node with LLM."""
        # Prepare state with retrieved docs
        state = graph_builder.retriever_node(sample_query_state)
        result_state = graph_builder.answer_gen_node(state)
        
        assert result_state.generated_answer is not None
        assert "This is a test answer generated by the LLM." in result_state.generated_answer
        assert len(result_state.messages) == 2  # Original + AI response
        
        # Verify LLM was called
        mock_llm.invoke.assert_called()

    def test_answer_gen_node_no_llm(self, sample_query_state):
        """Test answer generation node without LLM."""
        builder = MasterGraphBuilder()  # No LLM
        state = builder.retriever_node(sample_query_state)
        result_state = builder.answer_gen_node(state)
        
        assert result_state.generated_answer is None

    def test_human_review_node(self, graph_builder, sample_query_state):
        """Test human review node."""
        # Prepare state with generated answer
        state = graph_builder.retriever_node(sample_query_state)
        state = graph_builder.answer_gen_node(state)
        result_state = graph_builder.human_review_node(state)
        
        assert result_state.human_feedback == "approved"
        assert result_state.final_answer == result_state.generated_answer

    def test_validated_store_node(self, graph_builder, sample_query_state, mock_vectorstore):
        """Test validated store node with vectorstore."""
        # Prepare state with final answer
        state = graph_builder.retriever_node(sample_query_state)
        state = graph_builder.answer_gen_node(state)
        state = graph_builder.human_review_node(state)
        result_state = graph_builder.validated_store_node(state)
        
        assert result_state.status == "validated"
        # Verify vectorstore was called
        mock_vectorstore.add_texts.assert_called()

    def test_validated_store_node_no_vectorstore(self, sample_query_state):
        """Test validated store node without vectorstore."""
        builder = MasterGraphBuilder()  # No vectorstore
        state = builder.retriever_node(sample_query_state)
        state = builder.answer_gen_node(state)
        state = builder.human_review_node(state)
        result_state = builder.validated_store_node(state)
        
        assert result_state.status == "validated"

    def test_build_graph(self, graph_builder):
        """Test graph compilation."""
        compiled_graph = graph_builder.build()
        
        assert compiled_graph is not None
        # Verify the graph has the expected structure
        # Note: We can't easily test the internal structure without accessing private attributes

    def test_full_ingest_workflow(self, graph_builder, sample_ingest_state, mock_vectorstore):
        """Test complete ingest workflow."""
        compiled_graph = graph_builder.build()
        
        # Run the workflow
        result = compiled_graph.invoke(sample_ingest_state)
        
        # LangGraph returns a dict with the final state
        final_state = result if isinstance(result, dict) else result
        assert final_state["status"] == "stored"
        assert final_state["chunks"] is not None
        assert final_state["embeddings"] is not None
        # Verify vectorstore was called
        mock_vectorstore.add_texts.assert_called()

    def test_full_query_workflow(self, graph_builder, sample_query_state, mock_llm, mock_retriever, mock_vectorstore):
        """Test complete query workflow."""
        compiled_graph = graph_builder.build()
        
        # Run the workflow
        result = compiled_graph.invoke(sample_query_state)
        
        # LangGraph returns a dict with the final state
        final_state = result if isinstance(result, dict) else result
        assert final_state["status"] == "validated"
        assert final_state["generated_answer"] is not None
        assert final_state["final_answer"] is not None
        assert final_state["human_feedback"] == "approved"
        assert final_state["retrieved_docs"] is not None
        
        # Verify all components were called
        mock_retriever.get_relevant_documents.assert_called()
        mock_llm.invoke.assert_called()
        mock_vectorstore.add_texts.assert_called()

    def test_error_handling(self, graph_builder):
        """Test error handling in the workflow."""
        compiled_graph = graph_builder.build()
        
        # Test with invalid state
        invalid_state = KnowledgeState(query_type="invalid")
        result = compiled_graph.invoke(invalid_state)
        
        # LangGraph returns a dict with the final state
        final_state = result if isinstance(result, dict) else result
        assert final_state["status"] == "error"
        assert "Unknown query_type" in (final_state["logs"] or [])

    # ============================================================================
    # REAL INTEGRATION TESTS
    # ============================================================================

    @pytest.mark.integration
    def test_real_llm_connection(self, real_graph_builder):
        """Test direct LLM connection and response."""
        try:
            # Test a simple prompt
            test_prompt = [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": "Say 'Hello from Smart Second Brain!' and nothing else."}
            ]
            
            response = real_graph_builder.llm.invoke(test_prompt)
            
            assert response is not None
            assert response.content is not None
            assert len(response.content) > 0
            
            logger.info("üîó LLM Connection Test:")
            logger.info(f"   Response: {response.content}")
            logger.info(f"   Model: {real_graph_builder.llm.model_name}")
            logger.info(f"   Provider: {'Azure OpenAI' if 'azure' in str(real_graph_builder.llm.openai_api_base).lower() else 'OpenAI'}")
            
        except Exception as e:
            logger.error(f"LLM connection test failed: {e}")
            pytest.fail(f"LLM connection test failed: {e}")

    @pytest.mark.integration
    def test_real_llm_answer_generation(self, real_graph_builder, sample_query_state):
        """Test answer generation with real OpenAI LLM."""
        # Prepare state with retrieved docs
        state = real_graph_builder.retriever_node(sample_query_state)
        result_state = real_graph_builder.answer_gen_node(state)
        
        assert result_state.generated_answer is not None
        assert len(result_state.generated_answer) > 10
        assert len(result_state.messages) == 2  # Original + AI response
        
        logger.info(f"ü§ñ Real LLM Response: {result_state.generated_answer}")

    @pytest.mark.integration
    def test_real_document_ingestion_with_vectorstore(self, real_graph_builder, sample_documents):
        """Test document ingestion with real vector store."""
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set in .env file")
        
        try:
            # Create real vector store with proper API configuration
            openai_api_key = os.getenv("OPENAI_API_KEY")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT_URL")
            
            # Get embedding model from environment
            embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            api_version = os.getenv("API_VERSION", "2024-02-15-preview")
            
            if azure_endpoint and azure_endpoint != "https://your-resource-name.openai.azure.com/":
                # Use AzureOpenAIEmbeddings for Azure endpoints
                deployment = "text-embedding-3-small"
                logger.info(f"üîó Using Azure OpenAI embeddings: {embedding_model}")
                logger.info(f"üöÄ Using deployment: {deployment}")
                embeddings = AzureOpenAIEmbeddings(
                    azure_deployment=deployment,
                    openai_api_version=api_version,
                    azure_endpoint=azure_endpoint,
                    openai_api_key=openai_api_key
                )
            else:
                embeddings = OpenAIEmbeddings(
                    model=embedding_model,
                    openai_api_key=openai_api_key
                )
            
            vectorstore = Chroma(embedding_function=embeddings)
            
            # Update builder with real vector store
            real_graph_builder.vectorstore = vectorstore
            
            # Test document ingestion
            for i, doc_text in enumerate(sample_documents):
                state = KnowledgeState(
                    query_type="ingest",
                    raw_document=doc_text,
                    metadata={"source": f"test_doc_{i}", "timestamp": "2024-01-01T00:00:00Z"}
                )
                
                # Run ingestion workflow
                compiled_graph = real_graph_builder.build()
                result = compiled_graph.invoke(state)
                
                assert result.status == "stored"
                assert result.chunks is not None
                assert result.embeddings is not None
                assert len(result.chunks) > 0
                assert len(result.embeddings) == len(result.chunks)
                
                logger.info(f"‚úÖ Document {i+1} ingested successfully")
            
            # Test retrieval
            query_state = KnowledgeState(
                query_type="query",
                user_input="What is a knowledge graph?",
                messages=[{"role": "user", "content": "What is a knowledge graph?"}]
            )
            
            # Create retriever from vector store
            retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
            real_graph_builder.retriever = retriever
            
            # Run query workflow
            result = compiled_graph.invoke(query_state)
            
            assert result.status == "validated"
            assert result.generated_answer is not None
            assert result.retrieved_docs is not None
            assert len(result.retrieved_docs) > 0
            
            logger.info(f"üîç Retrieved {len(result.retrieved_docs)} documents")
            logger.info(f"ü§ñ Generated Answer: {result.generated_answer}")
            
        except Exception as e:
            pytest.fail(f"Real integration test failed: {e}")

    @pytest.mark.integration
    def test_real_workflow_with_text_splitter(self, real_graph_builder, sample_documents):
        """Test complete workflow with real text splitting and embeddings."""
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set in .env file")
        
        try:
            # Create real components with proper API configuration
            openai_api_key = os.getenv("OPENAI_API_KEY")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT_URL")
            
            # Get embedding model and API version from environment
            embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            api_version = os.getenv("API_VERSION", "2024-02-15-preview")
            
            if azure_endpoint and azure_endpoint != "https://your-resource-name.openai.azure.com/":
                # Use AzureOpenAIEmbeddings for Azure endpoints
                logger.info(f"üîó Using Azure OpenAI embeddings: {embedding_model}")
                embeddings = AzureOpenAIEmbeddings(
                    azure_deployment=embedding_model,
                    openai_api_version=api_version,
                    azure_endpoint=azure_endpoint,
                    openai_api_key=openai_api_key
                )
            else:
                embeddings = OpenAIEmbeddings(
                    model=embedding_model,
                    openai_api_key=openai_api_key
                )
            
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=100,
                chunk_overlap=20,
                separators=["\n\n", "\n", " ", ""]
            )
            vectorstore = Chroma(embedding_function=embeddings)
            
            # Update builder
            real_graph_builder.vectorstore = vectorstore
            
            # Override chunk_doc_node to use real text splitter
            original_chunk_method = real_graph_builder.chunk_doc_node
            
            def real_chunk_doc_node(state: KnowledgeState):
                if state.raw_document:
                    chunks = text_splitter.split_text(state.raw_document)
                    state.chunks = chunks
                return state
            
            real_graph_builder.chunk_doc_node = real_chunk_doc_node
            
            # Test with a longer document
            long_document = "\n\n".join(sample_documents)
            state = KnowledgeState(
                query_type="ingest",
                raw_document=long_document,
                metadata={"source": "integration_test", "timestamp": "2024-01-01T00:00:00Z"}
            )
            
            # Run ingestion
            compiled_graph = real_graph_builder.build()
            result = compiled_graph.invoke(state)
            
            assert result.status == "stored"
            assert result.chunks is not None
            assert len(result.chunks) > 1  # Should be split into multiple chunks
            
            logger.info(f"‚úÖ Document split into {len(result.chunks)} chunks")
            
            # Test retrieval and answer generation
            query_state = KnowledgeState(
                query_type="query",
                user_input="Explain the Smart Second Brain system",
                messages=[{"role": "user", "content": "Explain the Smart Second Brain system"}]
            )
            
            retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
            real_graph_builder.retriever = retriever
            
            result = compiled_graph.invoke(query_state)
            
            assert result.status == "validated"
            assert result.generated_answer is not None
            assert len(result.generated_answer) > 50
            
            logger.info(f"ü§ñ Final Answer: {result.generated_answer}")
            
        except Exception as e:
            pytest.fail(f"Real workflow test failed: {e}")

    @pytest.mark.integration
    def test_real_performance_benchmark(self, real_graph_builder, sample_documents):
        """Benchmark performance with real components."""
        if not os.getenv("OPENAI_API_KEY"):
            pytest.skip("OPENAI_API_KEY not set in .env file")
        
        import time
        
        try:
            # Setup real components with proper API configuration
            openai_api_key = os.getenv("OPENAI_API_KEY")
            azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT_URL")
            
            # Get embedding model and API version from environment
            embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
            api_version = os.getenv("API_VERSION", "2024-02-15-preview")
            
            if azure_endpoint and azure_endpoint != "https://your-resource-name.openai.azure.com/":
                # Use AzureOpenAIEmbeddings for Azure endpoints
                deployment = "text-embedding-3-small"
                logger.info(f"üîó Using Azure OpenAI embeddings: {embedding_model}")
                logger.info(f"üöÄ Using deployment: {deployment}")
                embeddings = AzureOpenAIEmbeddings(
                    azure_deployment=deployment,
                    openai_api_version=api_version,
                    azure_endpoint=azure_endpoint,
                    openai_api_key=openai_api_key
                )
            else:
                embeddings = OpenAIEmbeddings(
                    model=embedding_model,
                    openai_api_key=openai_api_key
                )
            
            vectorstore = Chroma(embedding_function=embeddings)
            real_graph_builder.vectorstore = vectorstore
            
            # Benchmark ingestion
            start_time = time.time()
            
            for i, doc_text in enumerate(sample_documents[:3]):  # Test with first 3 docs
                state = KnowledgeState(
                    query_type="ingest",
                    raw_document=doc_text,
                    metadata={"source": f"benchmark_doc_{i}"}
                )
                
                compiled_graph = real_graph_builder.build()
                result = compiled_graph.invoke(state)
                
                assert result.status == "stored"
            
            ingestion_time = time.time() - start_time
            logger.info(f"‚è±Ô∏è  Ingestion time for 3 documents: {ingestion_time:.2f} seconds")
            
            # Benchmark query
            start_time = time.time()
            
            retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
            real_graph_builder.retriever = retriever
            
            query_state = KnowledgeState(
                query_type="query",
                user_input="What are the key features of AI systems?",
                messages=[{"role": "user", "content": "What are the key features of AI systems?"}]
            )
            
            result = compiled_graph.invoke(query_state)
            
            query_time = time.time() - start_time
            logger.info(f"‚è±Ô∏è  Query time: {query_time:.2f} seconds")
            
            assert result.status == "validated"
            assert result.generated_answer is not None
            
            logger.info(f"üìä Performance Summary:")
            logger.info(f"   - Ingestion: {ingestion_time:.2f}s for 3 docs")
            logger.info(f"   - Query: {query_time:.2f}s")
            logger.info(f"   - Total: {ingestion_time + query_time:.2f}s")
            
        except Exception as e:
            pytest.fail(f"Performance benchmark failed: {e}")


if __name__ == "__main__":
    # Run the tests
    pytest.main([__file__, "-v"])
